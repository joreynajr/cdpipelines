{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cdpipelines import general\n",
    "reload(general)\n",
    "from cdpipelines import wgs_hla_typing\n",
    "reload(wgs_hla_typing)\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "output_dir = '/home/joreyna/trash/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WGS_HLAJobScript_extended(wgs_hla_typing.WGS_HLAJobScript):\n",
    "    \n",
    "    def select_vbseq_alleles(self, raw_vbseq, top_selections, hla_bed, hla_fasta):\n",
    "        \"\"\"\n",
    "        raw_vbseq: str\n",
    "            Path to the raw vbseq results (*.vbseq.avgdp')\n",
    "            \n",
    "        top_selection: list\n",
    "            Indexes for selecting some allele based on the descent order.\n",
    "            \n",
    "        hla_bed: str\n",
    "            Bed file with the coordinates of all HLA types. \n",
    "        \n",
    "        hla_fasta: str\n",
    "            Fasta file with the sequences of all HLA types.\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        # DETERMINING the top allele for each HLA gene.\n",
    "        raw_vbseq = pd.read_table(raw_vbseq, header=None, names=['allele', 'mean_read_depth'])\n",
    "        raw_vbseq['gene'] = [x[0] for x in raw_vbseq.allele.str.split('*')]\n",
    "        gene_grps = raw_vbseq.groupby('gene')\n",
    "        select_alleles = gene_grps.apply(\\\n",
    "              lambda x: x.sort_values('mean_read_depth', ascending=False).iloc[top_selections])\n",
    "        select_alleles.reset_index(drop=True, inplace=True)\n",
    "        select_alleles.set_index('allele', inplace=True)\n",
    "\n",
    "        # PUllING the coordinates for the alleles of interest.  \n",
    "        allele_coords = pd.read_table(hla_bed, names = ['accession', 'start', 'end', 'allele'], header=None)\n",
    "        allele_coords = allele_coords[allele_coords['allele'].isin(select_alleles.index.tolist())]\n",
    "        \n",
    "        # SAVING the coordinates \n",
    "        output_bed = os.path.join(self.outdir, '{}_select_alleles.bed'.format(self.sample_name))\n",
    "        allele_coords.to_csv(output_bed, index=False, header=False, sep='\\t')\n",
    "        \n",
    "        # SAVING a version with reversed accession and allele locations\n",
    "        rev_output_bed = os.path.join(self.outdir, '{}_rev_select_alleles.bed'.format(self.sample_name))\n",
    "        rev_allele_coords = allele_coords[[ 'allele', 'start', 'end', 'accession']]\n",
    "        rev_allele_coords.to_csv(rev_output_bed, index=False, header=False, sep='\\t')\n",
    "\n",
    "        # GENERATING the fasta file \n",
    "        output_fasta = os.path.join(self.outdir, '{}_select_alleles.fasta'.format(self.sample_name))\n",
    "        cmd = 'bedtools getfasta -fi {} -bed {} -fo {} -name'.format(hla_fasta, output_bed, output_fasta)\n",
    "        \n",
    "        lines = self._add_execution_date(cmd)\n",
    "        with open(self.filename, \"a\") as f:\n",
    "            lines = '\\n'.join(lines)\n",
    "            f.write(lines)\n",
    "        \n",
    "        return output_bed, rev_output_bed, output_fasta \n",
    "    \n",
    "    def bwa_map(\n",
    "        self,\n",
    "        ref,\n",
    "        r1_fastq,\n",
    "        r2_fastq,\n",
    "        stringent=False,\n",
    "        suffix=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Aligning paired end data to specific allele reference sequences using bwa.\n",
    "\n",
    "        - bwa P is used for paired-end data.\n",
    "        - samtools -F 4 is used to extract mapped reads only.\n",
    "\n",
    "\n",
    "        Parameters\n",
    "        __________\n",
    "        hla_ref : str\n",
    "            Path to hla_ref file.\n",
    "        r1_fastq : str\n",
    "            Path to input r1 fastq file.\n",
    "        r2_fastq : str\n",
    "            Path to input r2 fastq file.\n",
    "            Path to bowtie2.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out_bam : str\n",
    "            Path to bam file.\n",
    "        \"\"\"\n",
    "        if suffix: \n",
    "            out_bam = os.path.join(self.outdir, '{}_{}.bam'.format(self.sample_name, suffix))\n",
    "        else: \n",
    "            out_bam = os.path.join(self.outdir, '{}.bam'.format(self.sample_name))\n",
    "\n",
    "        if stringent:\n",
    "            cmd = 'bwa mem -P -B 40 -O 60 -E 10 -L 10000 -t {} {} {} {} | samtools view -F 4 -b - > {}'.\\\n",
    "                format(self.threads,\n",
    "                ref,\n",
    "                r1_fastq,\n",
    "                r2_fastq,\n",
    "                out_bam)\n",
    "        else:\n",
    "            cmd = 'bwa mem -P -L 10000 -t {} {} {} {} | samtools view -F 4 -b - > {}'.\\\n",
    "                format(self.threads,\n",
    "                ref,\n",
    "                r1_fastq,\n",
    "                r2_fastq,\n",
    "                out_bam)\n",
    "\n",
    "        lines = self._add_execution_date(cmd)\n",
    "        with open(self.filename, 'a') as f:\n",
    "            f.write('\\n'.join(lines))\n",
    "        return out_bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a sample job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe_dir = os.path.join(output_dir, 'align_first_allele')\n",
    "sample_name = 'c17006e1-8649-4e9e-ba4f-7bd4ee752244_ds100'\n",
    "sample = os.path.join(pipe_dir, sample_name)\n",
    "job_suffix = 'testing'\n",
    "threads = 1\n",
    "memory = 4\n",
    "queue = None\n",
    "conda_env = 'hla'\n",
    "modules = 'bwa,samtools'\n",
    "wait_for = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_vbseq = '/projects/CARDIPS/pipeline/HLA_Typing/sample/WGS_Main/{0}/hla/{0}.vbseq.avgdp'.format(sample_name)\n",
    "top_choices = [1]\n",
    "hla_bed = '/repos/cardips-pipelines/HLA_Typing/sources/IPD_IMGT_HLA_Release_3.29.0_2017_07_27/hla_gen.fasta.bed'\n",
    "hla_fasta = '/repos/cardips-pipelines/HLA_Typing/sources/IPD_IMGT_HLA_Release_3.29.0_2017_07_27/hla_gen.fasta'\n",
    "\n",
    "r1_fastq = '/projects/CARDIPS/pipeline/HLA_Typing/sample/WGS_Main/{0}/reads/{0}_R1.fastq'.format(sample_name)\n",
    "r2_fastq = '/projects/CARDIPS/pipeline/HLA_Typing/sample/WGS_Main/{0}/reads/{0}_R2.fastq'.format(sample_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Selecting alleles \n",
    "job = WGS_HLAJobScript_extended(sample_name, 'select_alleles', os.path.join(sample, 'qc'), 1, 1, \n",
    "                                queue = queue, \n",
    "                                conda_env=conda_env,\n",
    "                                modules = 'bedtools,bwa')\n",
    "select_alleles_job = job.jobname\n",
    "job.add_input_file(raw_vbseq)\n",
    "job.add_input_file(hla_bed)\n",
    "job.add_input_file(hla_fasta)\n",
    "select_alleles_bed, rev_select_alleles_bed, select_alleles_fasta = \\\n",
    "        job.select_vbseq_alleles(raw_vbseq, top_choices, hla_bed, hla_fasta)\n",
    "select_alleles_bwa_indexes = job.bwa_index(select_alleles_fasta)\n",
    "job.add_output_file(output_bed)\n",
    "job.add_output_file(output_fasta)\n",
    "job.write_end()\n",
    "if not job.delete_sh:\n",
    "    submit_commands.append(job.sge_submit_command())\n",
    "\n",
    "## Aligning reads reference \n",
    "job = WGS_HLAJobScript_extended(sample_name, 'align_to_select_alleles', os.path.join(sample, 'qc'), 1, 4, \n",
    "                                queue = queue, \n",
    "                                conda_env=conda_env,\n",
    "                                modules = 'bwa,samtools,sambamba',\n",
    "                                wait_for = [select_alleles_job])\n",
    "aln_select_jobname = job.jobname\n",
    "\n",
    "job.add_input_file(r1_fastq)\n",
    "job.add_input_file(r2_fastq)\n",
    "select_alleles_bam = job.bwa_map(select_alleles_fasta, r1_fastq, r2_fastq, suffix='select_alleles')\n",
    "select_alleles_sorted_bam = job.sambamba_sort(select_alleles_bam, suffix='select_alleles')\n",
    "select_alleles_sorted_bai = job.sambamba_index(select_alleles_sorted_bam, suffix='select_alleles')\n",
    "\n",
    "job.add_output_file(select_alleles_bam)\n",
    "job.add_output_file(select_alleles_sorted_bam)\n",
    "job.add_output_file(select_alleles_sorted_bai)\n",
    "job.write_end()\n",
    "if not job.delete_sh:\n",
    "    submit_commands.append(job.sge_submit_command())\n",
    "\n",
    "## Running mpileup\n",
    "job = WGS_HLAJobScript_extended(sample_name, 'mpileup_select_alleles', os.path.join(sample, 'qc'), 1, 4, \n",
    "                                queue = queue, \n",
    "                                conda_env=conda_env,\n",
    "                                modules = 'samtools/1.4',\n",
    "                                wait_for = [aln_select_jobname])\n",
    "mpile_select_jobname = job.jobname\n",
    "job.add_input_file(select_alleles_sorted_bam)\n",
    "job.add_input_file(select_alleles_fasta)\n",
    "job.add_input_file(hla_bed)\n",
    "select_alleles_mpile, select_alleles_mpile_parsed = job.samtools_mpileup(select_alleles_sorted_bam, select_alleles_fasta, \n",
    "                                   rev_select_alleles_bed, suffix='select_alleles')\n",
    "job.add_output_file(select_alleles_mpile)\n",
    "job.write_end()\n",
    "if not job.delete_sh:\n",
    "    submit_commands.append(job.sge_submit_command())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table = pd.read_table(select_alleles_mpile_parsed)\n",
    "table['total_a'] = table['A'] + table['a']\n",
    "table['total_c'] = table['C'] + table['c']\n",
    "table['total_g'] = table['G'] + table['g']\n",
    "table['total_t'] = table['T'] + table['t']\n",
    "table['total_snps']  = table[['A', 'C', 'G', 'T', 'a', 'c', 'g', 't']].sum(axis=1)\n",
    "table['proportion_a']  = table['total_a'] * 100 / table['total_snps']\n",
    "table['proportion_c']  = table['total_c'] * 100 / table['total_snps']\n",
    "table['proportion_g']  = table['total_g'] * 100 / table['total_snps']\n",
    "table['proportion_t']  = table['total_t'] * 100 / table['total_snps']\n",
    "table = table[['chr', 'loc', 'ref', 'proportion_a', 'proportion_c', 'proportion_g', 'proportion_t']]\n",
    "\n",
    "hets = []\n",
    "for index, sr in table.iterrows():\n",
    "    ref_proportion = sr['proportion_{}'.format(sr.ref.lower())]\n",
    "    \n",
    "    if ref_proportion >= 40 and ref_proportion <= 60:\n",
    "        hets.append(True)\n",
    "    else:\n",
    "        hets.append(False)\n",
    "table['hets'] = hets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hla)",
   "language": "python",
   "name": "hla"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
